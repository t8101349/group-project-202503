{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c52bbc412434b17a84d0abdcd780ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_83fe6d93a14c4603ac4cd2ba7131caa6"
          }
        },
        "18239121f1784810883e944d61d7143e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792af07941364fe3adfa952d98fbc4b6",
            "placeholder": "​",
            "style": "IPY_MODEL_ef1d2abf34764bc798bb8c2d86b5affb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "63f17908b6ad478aa95b8f30d61d282b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_91225eb6207f442a8ff9b317e1f47613",
            "placeholder": "​",
            "style": "IPY_MODEL_cf5bee7a39ca42e3a51406e525641b01",
            "value": ""
          }
        },
        "7a807f3d370a46799b22fd753371a958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2524ddbc126b4ed9ac0e3f1e2e378162",
            "style": "IPY_MODEL_df923a7ae26b4d1aa6732f03b73128ab",
            "value": true
          }
        },
        "f0b7d659174b4834ab7f602b64699684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1a848546bdb6443686f504653fa04c93",
            "style": "IPY_MODEL_438e3fbeccf7486ebd39d27ad9e2d192",
            "tooltip": ""
          }
        },
        "d52b9da4c7a64d96989d96016511bccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc93256ce13340edb694e476dfa2809b",
            "placeholder": "​",
            "style": "IPY_MODEL_662448e5726045778f29ac1539113073",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "83fe6d93a14c4603ac4cd2ba7131caa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "792af07941364fe3adfa952d98fbc4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1d2abf34764bc798bb8c2d86b5affb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91225eb6207f442a8ff9b317e1f47613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5bee7a39ca42e3a51406e525641b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2524ddbc126b4ed9ac0e3f1e2e378162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df923a7ae26b4d1aa6732f03b73128ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a848546bdb6443686f504653fa04c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438e3fbeccf7486ebd39d27ad9e2d192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "dc93256ce13340edb694e476dfa2809b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662448e5726045778f29ac1539113073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30883ef1dd504f1ebb609f383d00ee4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5385a68c3e9d49f2ac4ef04aec8b398c",
            "placeholder": "​",
            "style": "IPY_MODEL_19636cc4236448b4ab956eb0c3ce255a",
            "value": "Connecting..."
          }
        },
        "5385a68c3e9d49f2ac4ef04aec8b398c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19636cc4236448b4ab956eb0c3ce255a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t8101349/group-project-202503/blob/main/gradio_web_0318.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install gradio\n",
        "!pip install rdkit\n",
        "!pip install scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIHfm3wryrz7",
        "outputId": "25260f75-d923-415e-b37d-32b8b16c8836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.21.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.21.0 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.0 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.2.2\n",
            "Collecting xgboost==2.0.3\n",
            "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.0.3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.0.3) (1.14.1)\n",
            "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.4\n",
            "    Uninstalling xgboost-2.1.4:\n",
            "      Successfully uninstalled xgboost-2.1.4\n",
            "Successfully installed xgboost-2.0.3\n",
            "Requirement already satisfied: lightgbm==4.5.0 in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm==4.5.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm==4.5.0) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import traceback\n",
        "from gradio.themes import Base\n",
        "from process import predict_process\n",
        "\n",
        "class AppState:\n",
        "    def __init__(self):\n",
        "        self.df = None\n",
        "        self.result_df = None\n",
        "        self.file_uploaded = False\n",
        "        self.prediction_done = False\n",
        "\n",
        "state = AppState()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "def smiles_to_morgan_fingerprint(smiles, n_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(n_bits, dtype=int)\n",
        "    else:\n",
        "        generator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
        "        return np.array(generator.GetFingerprint(mol), dtype=int)\n",
        "\n",
        "\n",
        "def predict_process(df):\n",
        "    # 載入模型\n",
        "    model_path = hf_hub_download(repo_id=\"sinanju/model_voting\", filename=\"voting_model.bin\")\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # 對 \"molecule_smiles\" 欄位進行轉換\n",
        "    df[\"molecule_smiles\"] = df[\"molecule_smiles\"].apply(lambda x: smiles_to_morgan_fingerprint(x))\n",
        "    df.columns = df.columns.astype(str)\n",
        "\n",
        "    # 轉成 int8 以節省記憶體\n",
        "    int_cols = df.select_dtypes(include=['int64']).columns\n",
        "    for col in int_cols:\n",
        "        df[col] = df[col].astype(np.int8)\n",
        "\n",
        "    # 處理指紋數據和蛋白質編碼\n",
        "    fingerprints_df = pd.DataFrame(df['molecule_smiles'].to_list())\n",
        "    protein_onehot = pd.get_dummies(df[\"protein_name\"], prefix=\"protein\").astype(int).reset_index(drop=True)\n",
        "    X_test = pd.concat([fingerprints_df, protein_onehot], axis=1)\n",
        "    X_test.columns = X_test.columns.astype(str)  # 修復點：統一欄位名稱為字串\n",
        "\n",
        "    # 預測機率並轉為二元分類\n",
        "    probabilities = model.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.5\n",
        "    predictions = (probabilities >= threshold).astype(int)\n",
        "\n",
        "    # 產生新的 id\n",
        "    df['id'] = range(1, 1 + len(df))\n",
        "\n",
        "    # 建立結果 DataFrame\n",
        "    result_df = pd.DataFrame({\n",
        "        'id': df['id'],\n",
        "        'molecule_smiles': df['molecule_smiles'],\n",
        "        'binds': predictions\n",
        "    })\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def confirm_file(file):\n",
        "    if file is None:\n",
        "        return \"請上傳分子數據集！\", False\n",
        "    try:\n",
        "        original_filename = file.name if hasattr(file, \"name\") else \"未知檔案\"\n",
        "        if original_filename.endswith('.csv'):\n",
        "            df = pd.read_csv(file.name)\n",
        "        elif original_filename.endswith('.parquet'):\n",
        "            df = pd.read_parquet(file.name)\n",
        "        else:\n",
        "            return f\"不支援的檔案格式：{original_filename}！僅支援 .csv 和 .parquet\", False\n",
        "        required_columns = [\"molecule_smiles\", \"protein_name\"]\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_columns:\n",
        "            return f\"檔案缺少必要的欄位：{', '.join(missing_columns)}\", False\n",
        "        if len(df) > 500000:\n",
        "            return \"資料筆數超過 50 萬筆，請減少資料量！\", False\n",
        "        state.df = df\n",
        "        state.file_uploaded = True\n",
        "        state.prediction_done = False\n",
        "        return f\"✅ 已成功上傳檔案：{original_filename}，共 {len(df)} 筆資料\", True\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"檔案處理錯誤：{str(e)}\\n{error_details}\")\n",
        "        return f\"❌ 檔案處理錯誤：{str(e)}\", False\n",
        "\n",
        "def run_prediction():\n",
        "    if not state.file_uploaded or state.df is None:\n",
        "        return \"❌ 請先上傳並確認檔案！\", False\n",
        "\n",
        "    # 檢查缺失值\n",
        "    if state.df.isnull().values.any():\n",
        "        missing_info = state.df.isnull().sum()\n",
        "        missing_summary = missing_info[missing_info > 0].to_dict()\n",
        "        return f\"❌ 資料包含缺失值，請處理後再預測！缺失欄位: {missing_summary}\", False\n",
        "\n",
        "    try:\n",
        "        result_df = predict_process(state.df)\n",
        "        state.result_df = result_df\n",
        "        state.prediction_done = True\n",
        "        return f\"✅ 預測完成！共處理 {len(result_df)} 筆資料\", True\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"預測錯誤：{str(e)}\\n{error_details}\")\n",
        "        return f\"❌ 預測錯誤：{str(e)}\", False\n",
        "\n",
        "def generate_file(format_choice):\n",
        "    import tempfile\n",
        "    import os\n",
        "    if not state.prediction_done or state.result_df is None:\n",
        "        return None, \"❌ 請先執行預測！\"\n",
        "    try:\n",
        "        temp_dir = tempfile.gettempdir()\n",
        "        if format_choice == \"CSV\":\n",
        "            filename = \"prediction.csv\"\n",
        "            filepath = os.path.join(temp_dir, filename)\n",
        "            state.result_df.to_csv(filepath, index=False)\n",
        "        else:\n",
        "            filename = \"prediction.parquet\"\n",
        "            filepath = os.path.join(temp_dir, filename)\n",
        "            state.result_df.to_parquet(filepath, index=False)\n",
        "        return filepath, f\"✅ 已生成 {filename}，點擊下方按鈕即可下載\"\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"生成檔案錯誤：{str(e)}\\n{error_details}\")\n",
        "        return None, f\"❌ 生成檔案錯誤：{str(e)}\"\n",
        "\n",
        "def update_button_status(status_text, button_value):\n",
        "    if \"✅\" in status_text:\n",
        "        return gr.update(interactive=True, value=\"執行預測\")\n",
        "    else:\n",
        "        return gr.update(interactive=False, value=\"執行預測\")\n",
        "\n",
        "custom_theme = Base(\n",
        "    primary_hue=\"cyan\",\n",
        "    secondary_hue=\"teal\",\n",
        "    neutral_hue=\"gray\"\n",
        ")\n",
        "\n",
        "with gr.Blocks(\n",
        "    theme=custom_theme,\n",
        "    title=\"新藥預測工具\",\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        width: 800px !important;\n",
        "        margin: auto !important;\n",
        "    }\n",
        "    h2 {\n",
        "        text-align: center;\n",
        "        font-size: 20px;\n",
        "    }\n",
        "    .gradient-title h1 {\n",
        "        background: linear-gradient(45deg, #13A9E6, #3DD69E);\n",
        "        -webkit-background-clip: text;\n",
        "        background-clip: text;\n",
        "        color: transparent;\n",
        "        text-align: center;\n",
        "        font-size: 52px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .gr-radio input[type=\"radio\"] {\n",
        "        accent-color: #13A9E6;\n",
        "    }\n",
        "    footer {\n",
        "        display: none !important;\n",
        "    }\n",
        "    .file-status {\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "    gr.Markdown(\"# 新藥預測工具\", elem_classes=[\"gradient-title\"])\n",
        "\n",
        "    with gr.Accordion(\"點此查看工具詳細說明\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "            **詳細說明：**\n",
        "            此工具可將SMILES形式的分子資料集根據一個預測分子與三種蛋白質標靶(sEH, BRD4, HSA)\n",
        "            是否結合的機器學習模型，來快速篩選出可能的藥物分子資料集。\n",
        "            **操作說明：**\n",
        "            1. 上傳分子數據集 (支援 CSV 與 Parquet 格式, 檔案大小上限50MB, 資料筆數上限50萬筆)\n",
        "            2. 確認上傳檔案\n",
        "            3. 執行預測\n",
        "            4. 選擇下載格式\n",
        "            5. 產生並下載預測檔案\n",
        "            **必要欄位說明：**\n",
        "            - molecule_smiles: 分子的SMILES表示法\n",
        "            - protein_name: 蛋白質名稱 (必須為 sEH, BRD4, HSA 其中之一)\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"## 上傳分子數據集\", elem_classes=[\"sub_title\"])\n",
        "\n",
        "        file_input = gr.File(\n",
        "            label=\"拖曳檔案至此或點擊上傳，上限50MB\",\n",
        "            file_types=[\".csv\", \".parquet\"],\n",
        "            type=\"filepath\"\n",
        "        )\n",
        "\n",
        "        confirm_btn = gr.Button(\"確認檔案\", variant=\"primary\")\n",
        "        file_status = gr.Textbox(\n",
        "            label=\"檔案狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        predict_btn = gr.Button(\"執行預測\", variant=\"primary\", interactive=False)\n",
        "        predict_status = gr.Textbox(\n",
        "            label=\"預測狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            download_format = gr.Radio(\n",
        "                choices=[\"CSV\", \"Parquet\"],\n",
        "                label=\"選擇下載格式\",\n",
        "                value=\"CSV\"\n",
        "            )\n",
        "\n",
        "        generate_btn = gr.Button(\"產生下載檔案\", variant=\"primary\", interactive=False)\n",
        "        generate_status = gr.Textbox(\n",
        "            label=\"檔案生成狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        download_btn = gr.DownloadButton(\n",
        "            label=\"下載預測結果\",\n",
        "            variant=\"primary\",\n",
        "            interactive=False,\n",
        "            visible=True\n",
        "        )\n",
        "\n",
        "    confirm_btn.click(\n",
        "        fn=confirm_file,\n",
        "        inputs=file_input,\n",
        "        outputs=[file_status, predict_btn]\n",
        "    ).then(\n",
        "        fn=update_button_status,\n",
        "        inputs=[file_status, predict_btn],\n",
        "        outputs=predict_btn\n",
        "    )\n",
        "\n",
        "    predict_btn.click(\n",
        "        fn=run_prediction,\n",
        "        inputs=None,\n",
        "        outputs=[predict_status, generate_btn]\n",
        "    ).then(\n",
        "        fn=lambda status_text, btn_value: gr.update(\n",
        "            interactive=\"✅\" in status_text,\n",
        "            value=\"產生下載檔案\"\n",
        "        ),\n",
        "        inputs=[predict_status, generate_btn],\n",
        "        outputs=generate_btn\n",
        "    )\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_file,\n",
        "        inputs=download_format,\n",
        "        outputs=[download_btn, generate_status]\n",
        "    ).then(\n",
        "        fn=lambda filepath, status: (\n",
        "            gr.update(\n",
        "                value=filepath,\n",
        "                interactive=True,\n",
        "                visible=True\n",
        "            ) if \"✅\" in status else gr.update(\n",
        "                value=None,\n",
        "                interactive=False,\n",
        "                visible=True\n",
        "            )\n",
        "        ),\n",
        "        inputs=[download_btn, generate_status],\n",
        "        outputs=download_btn\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        # 設定上傳檔案大小50MB限制\n",
        "        max_file_size=50 * 1024 * 1024\n",
        "    )"
      ],
      "metadata": {
        "id": "SzcR4GR_b3Xd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "ed8ec328-2e60-431e-9b1a-2ac2030ae681"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3d603ea51cc7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthemes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woTBhzRffgfk",
        "outputId": "c219a058-48b4-45c7-d8be-7b4d3865886b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2c52bbc412434b17a84d0abdcd780ad2",
            "18239121f1784810883e944d61d7143e",
            "63f17908b6ad478aa95b8f30d61d282b",
            "7a807f3d370a46799b22fd753371a958",
            "f0b7d659174b4834ab7f602b64699684",
            "d52b9da4c7a64d96989d96016511bccb",
            "83fe6d93a14c4603ac4cd2ba7131caa6",
            "792af07941364fe3adfa952d98fbc4b6",
            "ef1d2abf34764bc798bb8c2d86b5affb",
            "91225eb6207f442a8ff9b317e1f47613",
            "cf5bee7a39ca42e3a51406e525641b01",
            "2524ddbc126b4ed9ac0e3f1e2e378162",
            "df923a7ae26b4d1aa6732f03b73128ab",
            "1a848546bdb6443686f504653fa04c93",
            "438e3fbeccf7486ebd39d27ad9e2d192",
            "dc93256ce13340edb694e476dfa2809b",
            "662448e5726045778f29ac1539113073",
            "30883ef1dd504f1ebb609f383d00ee4c",
            "5385a68c3e9d49f2ac4ef04aec8b398c",
            "19636cc4236448b4ab956eb0c3ce255a"
          ]
        },
        "id": "bFwBcrClfhp0",
        "outputId": "a88bdf27-751a-47da-fb9f-67fd6dbc1d20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c52bbc412434b17a84d0abdcd780ad2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/spaces/weber8101349/my-medicine-predict-model\n",
        "%cd my-medicine-predict-model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Petr6qyefLqm",
        "outputId": "190b1d4e-e28e-4a2c-f619-86a0bb0dee68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'my-medicine-predict-model' already exists and is not an empty directory.\n",
            "/content/my-medicine-predict-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "gradio\n",
        "transformers\n",
        "torch\n",
        "pandas\n",
        "numpy\n",
        "rdkit\n",
        "scikit-learn\n",
        "xgboost\n",
        "lightgbm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCDRhC_IfpTE",
        "outputId": "24ab6310-a020-469b-b477-5bde15e366b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import traceback\n",
        "from gradio.themes import Base\n",
        "from process import predict_process\n",
        "\n",
        "class AppState:\n",
        "    def __init__(self):\n",
        "        self.df = None\n",
        "        self.result_df = None\n",
        "        self.file_uploaded = False\n",
        "        self.prediction_done = False\n",
        "\n",
        "state = AppState()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "def smiles_to_morgan_fingerprint(smiles, n_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(n_bits, dtype=int)\n",
        "    else:\n",
        "        generator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
        "        return np.array(generator.GetFingerprint(mol), dtype=int)\n",
        "\n",
        "\n",
        "def predict_process(df):\n",
        "    # 載入模型\n",
        "    model_path = hf_hub_download(repo_id=\"sinanju/model_voting\", filename=\"voting_model.bin\")\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # 對 \"molecule_smiles\" 欄位進行轉換\n",
        "    df[\"molecule_smiles\"] = df[\"molecule_smiles\"].apply(lambda x: smiles_to_morgan_fingerprint(x))\n",
        "    df.columns = df.columns.astype(str)\n",
        "\n",
        "    # 轉成 int8 以節省記憶體\n",
        "    int_cols = df.select_dtypes(include=['int64']).columns\n",
        "    for col in int_cols:\n",
        "        df[col] = df[col].astype(np.int8)\n",
        "\n",
        "    # 處理指紋數據和蛋白質編碼\n",
        "    fingerprints_df = pd.DataFrame(df['molecule_smiles'].to_list())\n",
        "    protein_onehot = pd.get_dummies(df[\"protein_name\"], prefix=\"protein\").astype(int).reset_index(drop=True)\n",
        "    X_test = pd.concat([fingerprints_df, protein_onehot], axis=1)\n",
        "    X_test.columns = X_test.columns.astype(str)  # 修復點：統一欄位名稱為字串\n",
        "\n",
        "    # 預測機率並轉為二元分類\n",
        "    probabilities = model.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.5\n",
        "    predictions = (probabilities >= threshold).astype(int)\n",
        "\n",
        "    # 產生新的 id\n",
        "    df['id'] = range(1, 1 + len(df))\n",
        "\n",
        "    # 建立結果 DataFrame\n",
        "    result_df = pd.DataFrame({\n",
        "        'id': df['id'],\n",
        "        'molecule_smiles': df['molecule_smiles'],\n",
        "        'binds': predictions\n",
        "    })\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def confirm_file(file):\n",
        "    if file is None:\n",
        "        return \"請上傳分子數據集！\", False\n",
        "    try:\n",
        "        original_filename = file.name if hasattr(file, \"name\") else \"未知檔案\"\n",
        "        if original_filename.endswith('.csv'):\n",
        "            df = pd.read_csv(file.name)\n",
        "        elif original_filename.endswith('.parquet'):\n",
        "            df = pd.read_parquet(file.name)\n",
        "        else:\n",
        "            return f\"不支援的檔案格式：{original_filename}！僅支援 .csv 和 .parquet\", False\n",
        "        required_columns = [\"molecule_smiles\", \"protein_name\"]\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_columns:\n",
        "            return f\"檔案缺少必要的欄位：{', '.join(missing_columns)}\", False\n",
        "        if len(df) > 500000:\n",
        "            return \"資料筆數超過 50 萬筆，請減少資料量！\", False\n",
        "        state.df = df\n",
        "        state.file_uploaded = True\n",
        "        state.prediction_done = False\n",
        "        return f\"✅ 已成功上傳檔案：{original_filename}，共 {len(df)} 筆資料\", True\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"檔案處理錯誤：{str(e)}\\n{error_details}\")\n",
        "        return f\"❌ 檔案處理錯誤：{str(e)}\", False\n",
        "\n",
        "def run_prediction():\n",
        "    if not state.file_uploaded or state.df is None:\n",
        "        return \"❌ 請先上傳並確認檔案！\", False\n",
        "\n",
        "    # 檢查缺失值\n",
        "    if state.df.isnull().values.any():\n",
        "        missing_info = state.df.isnull().sum()\n",
        "        missing_summary = missing_info[missing_info > 0].to_dict()\n",
        "        return f\"❌ 資料包含缺失值，請處理後再預測！缺失欄位: {missing_summary}\", False\n",
        "\n",
        "    try:\n",
        "        result_df = predict_process(state.df)\n",
        "        state.result_df = result_df\n",
        "        state.prediction_done = True\n",
        "        return f\"✅ 預測完成！共處理 {len(result_df)} 筆資料\", True\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"預測錯誤：{str(e)}\\n{error_details}\")\n",
        "        return f\"❌ 預測錯誤：{str(e)}\", False\n",
        "\n",
        "def generate_file(format_choice):\n",
        "    import tempfile\n",
        "    import os\n",
        "    if not state.prediction_done or state.result_df is None:\n",
        "        return None, \"❌ 請先執行預測！\"\n",
        "    try:\n",
        "        temp_dir = tempfile.gettempdir()\n",
        "        if format_choice == \"CSV\":\n",
        "            filename = \"prediction.csv\"\n",
        "            filepath = os.path.join(temp_dir, filename)\n",
        "            state.result_df.to_csv(filepath, index=False)\n",
        "        else:\n",
        "            filename = \"prediction.parquet\"\n",
        "            filepath = os.path.join(temp_dir, filename)\n",
        "            state.result_df.to_parquet(filepath, index=False)\n",
        "        return filepath, f\"✅ 已生成 {filename}，點擊下方按鈕即可下載\"\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"生成檔案錯誤：{str(e)}\\n{error_details}\")\n",
        "        return None, f\"❌ 生成檔案錯誤：{str(e)}\"\n",
        "\n",
        "def update_button_status(status_text, button_value):\n",
        "    if \"✅\" in status_text:\n",
        "        return gr.update(interactive=True, value=\"執行預測\")\n",
        "    else:\n",
        "        return gr.update(interactive=False, value=\"執行預測\")\n",
        "\n",
        "custom_theme = Base(\n",
        "    primary_hue=\"cyan\",\n",
        "    secondary_hue=\"teal\",\n",
        "    neutral_hue=\"gray\"\n",
        ")\n",
        "\n",
        "with gr.Blocks(\n",
        "    theme=custom_theme,\n",
        "    title=\"新藥預測工具\",\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        width: 800px !important;\n",
        "        margin: auto !important;\n",
        "    }\n",
        "    h2 {\n",
        "        text-align: center;\n",
        "        font-size: 20px;\n",
        "    }\n",
        "    .gradient-title h1 {\n",
        "        background: linear-gradient(45deg, #13A9E6, #3DD69E);\n",
        "        -webkit-background-clip: text;\n",
        "        background-clip: text;\n",
        "        color: transparent;\n",
        "        text-align: center;\n",
        "        font-size: 52px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .gr-radio input[type=\"radio\"] {\n",
        "        accent-color: #13A9E6;\n",
        "    }\n",
        "    footer {\n",
        "        display: none !important;\n",
        "    }\n",
        "    .file-status {\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "    gr.Markdown(\"# 新藥預測工具\", elem_classes=[\"gradient-title\"])\n",
        "\n",
        "    with gr.Accordion(\"點此查看工具詳細說明\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "            **詳細說明：**\n",
        "            此工具可將SMILES形式的分子資料集根據一個預測分子與三種蛋白質標靶(sEH, BRD4, HSA)\n",
        "            是否結合的機器學習模型，來快速篩選出可能的藥物分子資料集。\n",
        "            **操作說明：**\n",
        "            1. 上傳分子數據集 (支援 CSV 與 Parquet 格式, 檔案大小上限50MB, 資料筆數上限50萬筆)\n",
        "            2. 確認上傳檔案\n",
        "            3. 執行預測\n",
        "            4. 選擇下載格式\n",
        "            5. 產生並下載預測檔案\n",
        "            **必要欄位說明：**\n",
        "            - molecule_smiles: 分子的SMILES表示法\n",
        "            - protein_name: 蛋白質名稱 (必須為 sEH, BRD4, HSA 其中之一)\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"## 上傳分子數據集\", elem_classes=[\"sub_title\"])\n",
        "\n",
        "        file_input = gr.File(\n",
        "            label=\"拖曳檔案至此或點擊上傳，上限50MB\",\n",
        "            file_types=[\".csv\", \".parquet\"],\n",
        "            type=\"filepath\"\n",
        "        )\n",
        "\n",
        "        confirm_btn = gr.Button(\"確認檔案\", variant=\"primary\")\n",
        "        file_status = gr.Textbox(\n",
        "            label=\"檔案狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        predict_btn = gr.Button(\"執行預測\", variant=\"primary\", interactive=False)\n",
        "        predict_status = gr.Textbox(\n",
        "            label=\"預測狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            download_format = gr.Radio(\n",
        "                choices=[\"CSV\", \"Parquet\"],\n",
        "                label=\"選擇下載格式\",\n",
        "                value=\"CSV\"\n",
        "            )\n",
        "\n",
        "        generate_btn = gr.Button(\"產生下載檔案\", variant=\"primary\", interactive=False)\n",
        "        generate_status = gr.Textbox(\n",
        "            label=\"檔案生成狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        download_btn = gr.DownloadButton(\n",
        "            label=\"下載預測結果\",\n",
        "            variant=\"primary\",\n",
        "            interactive=False,\n",
        "            visible=True\n",
        "        )\n",
        "\n",
        "    confirm_btn.click(\n",
        "        fn=confirm_file,\n",
        "        inputs=file_input,\n",
        "        outputs=[file_status, predict_btn]\n",
        "    ).then(\n",
        "        fn=update_button_status,\n",
        "        inputs=[file_status, predict_btn],\n",
        "        outputs=predict_btn\n",
        "    )\n",
        "\n",
        "    predict_btn.click(\n",
        "        fn=run_prediction,\n",
        "        inputs=None,\n",
        "        outputs=[predict_status, generate_btn]\n",
        "    ).then(\n",
        "        fn=lambda status_text, btn_value: gr.update(\n",
        "            interactive=\"✅\" in status_text,\n",
        "            value=\"產生下載檔案\"\n",
        "        ),\n",
        "        inputs=[predict_status, generate_btn],\n",
        "        outputs=generate_btn\n",
        "    )\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_file,\n",
        "        inputs=download_format,\n",
        "        outputs=[download_btn, generate_status]\n",
        "    ).then(\n",
        "        fn=lambda filepath, status: (\n",
        "            gr.update(\n",
        "                value=filepath,\n",
        "                interactive=True,\n",
        "                visible=True\n",
        "            ) if \"✅\" in status else gr.update(\n",
        "                value=None,\n",
        "                interactive=False,\n",
        "                visible=True\n",
        "            )\n",
        "        ),\n",
        "        inputs=[download_btn, generate_status],\n",
        "        outputs=download_btn\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        # 設定上傳檔案大小50MB限制\n",
        "        max_file_size=50 * 1024 * 1024\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB1GpRXMfpWn",
        "outputId": "415cce5e-c735-4507-a3b4-9a2add17a272"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27q5kBm9h3dv",
        "outputId": "37f41e18-b44e-44c3-ca6d-42f5bbe70969"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   app.py\u001b[m\n",
            "\t\u001b[32mnew file:   requirements.txt\u001b[m\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   app.py\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"First commit from Colab\"\n",
        "!git push\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Y9xJ1DgmUV",
        "outputId": "f5430d5f-48db-4f51-a0fe-2de542fd92fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@1bad210cf151.(none)')\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m 'Add application file'\n",
        "!git push\n"
      ],
      "metadata": {
        "id": "zMhc4RBWnb-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}