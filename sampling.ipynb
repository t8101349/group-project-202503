{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t8101349/group-project-202503/blob/main/sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip insall pandas\n",
        "# !pip install tqdm\n",
        "# !pip install pickle"
      ],
      "metadata": {
        "id": "fknS7Q8ESR62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO75HaxXRUlE"
      },
      "outputs": [],
      "source": [
        "# åˆ†å¸ƒçµ±è¨ˆ\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "# åƒæ•¸è¨­å®š\n",
        "filename = \"train.csv\"\n",
        "chunksize = 1_000_000\n",
        "bb_columns = [\"buildingblock1_smiles\", \"buildingblock2_smiles\", \"buildingblock3_smiles\"]\n",
        "\n",
        "# è¨ˆç®—åˆ†å±¤åˆ†å¸ƒ\n",
        "def compute_strata_counts(bb_col):\n",
        "    print(f\"ğŸ” çµ±è¨ˆ {bb_col} åˆ†å±¤åˆ†å¸ƒ...\")\n",
        "    strata_counts = {\"pos\": {}, \"neg\": {}}\n",
        "    for chunk in tqdm(pd.read_csv(filename, chunksize=chunksize, usecols=[bb_col, \"binds\"]), desc=f\"Counting {bb_col}\"):\n",
        "        for bb, group in chunk.groupby(bb_col):\n",
        "            pos_count = len(group[group[\"binds\"] == 1])\n",
        "            neg_count = len(group[group[\"binds\"] == 0])\n",
        "            strata_counts[\"pos\"][bb] = strata_counts[\"pos\"].get(bb, 0) + pos_count\n",
        "            strata_counts[\"neg\"][bb] = strata_counts[\"neg\"].get(bb, 0) + neg_count\n",
        "    total_pos = sum(strata_counts[\"pos\"].values())\n",
        "    total_neg = sum(strata_counts[\"neg\"].values())\n",
        "    return {\"strata_counts\": strata_counts, \"total_pos\": total_pos, \"total_neg\": total_neg}\n",
        "\n",
        "# åŸ·è¡Œä¸¦å„²å­˜\n",
        "strata_data = {}\n",
        "for bb_col in bb_columns:\n",
        "    strata_data[bb_col] = compute_strata_counts(bb_col)\n",
        "    print(f\"{bb_col} - ç¸½æ­£é¡: {strata_data[bb_col]['total_pos']}, ç¸½è² é¡: {strata_data[bb_col]['total_neg']}\")\n",
        "\n",
        "# å„²å­˜é è™•ç†è³‡æ–™\n",
        "with open(\"strata_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(strata_data, f)\n",
        "print(\"âœ… åˆ†å¸ƒçµ±è¨ˆå·²å„²å­˜è‡³ 'strata_data.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æŠ½æ¨£\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "# è¼‰å…¥é è™•ç†è³‡æ–™\n",
        "with open(\"strata_data.pkl\", \"rb\") as f:\n",
        "    strata_data = pickle.load(f)\n",
        "\n",
        "# åƒæ•¸è¨­å®š å¯èª¿æ•´ç‰¹å¾µæŠ½æ¨£æ¯”ä¾‹èˆ‡æ­£è² é¡æ¯”ä¾‹\n",
        "filename = \"train.csv\"\n",
        "chunksize = 1_000_000\n",
        "targets = [\n",
        "    {\"bb\": \"buildingblock1_smiles\", \"pos\": 80000, \"neg\": 240000}, # ç‰¹å¾µä¸€\n",
        "    {\"bb\": \"buildingblock2_smiles\", \"pos\": 10000, \"neg\": 30000}, # ç‰¹å¾µäºŒ\n",
        "    {\"bb\": \"buildingblock3_smiles\", \"pos\": 10000, \"neg\": 30000}, # ç‰¹å¾µä¸‰\n",
        "]\n",
        "\n",
        "# æŠ½æ¨£å‡½æ•¸\n",
        "def stratified_sample(bb_col, pos_target, neg_target, strata_data):\n",
        "    strata_counts = strata_data[bb_col][\"strata_counts\"]\n",
        "    total_pos = strata_data[bb_col][\"total_pos\"]\n",
        "    total_neg = strata_data[bb_col][\"total_neg\"]\n",
        "\n",
        "    print(f\"ğŸ² é€²è¡Œ {bb_col} åˆ†å±¤æŠ½æ¨£...\")\n",
        "    pos_samples = []\n",
        "    neg_samples = []\n",
        "    required_cols = [\"molecule_smiles\", \"buildingblock1_smiles\", \"buildingblock2_smiles\", \"buildingblock3_smiles\", \"protein_name\", \"binds\"]\n",
        "\n",
        "    for chunk in tqdm(pd.read_csv(filename, chunksize=chunksize, usecols=required_cols), desc=f\"Sampling {bb_col}\"):\n",
        "        for bb, group in chunk.groupby(bb_col):\n",
        "            pos_chunk = group[group[\"binds\"] == 1]\n",
        "            neg_chunk = group[group[\"binds\"] == 0]\n",
        "\n",
        "            pos_size = min(len(pos_chunk), int(pos_target * (strata_counts[\"pos\"].get(bb, 0) / total_pos)))\n",
        "            neg_size = min(len(neg_chunk), int(neg_target * (strata_counts[\"neg\"].get(bb, 0) / total_neg)))\n",
        "\n",
        "            if pos_size > 0 and len(pos_samples) < pos_target:\n",
        "                pos_sample = pos_chunk.sample(n=min(pos_size, pos_target - len(pos_samples)), random_state=42)\n",
        "                pos_samples.append(pos_sample)\n",
        "\n",
        "            if neg_size > 0 and len(neg_samples) < neg_target:\n",
        "                neg_sample = neg_chunk.sample(n=min(neg_size, neg_target - len(neg_samples)), random_state=42)\n",
        "                neg_samples.append(neg_sample)\n",
        "\n",
        "        if len(pos_samples) >= pos_target and len(neg_samples) >= neg_target:\n",
        "            break\n",
        "\n",
        "    df = pd.concat(pos_samples + neg_samples, ignore_index=True)\n",
        "    df_pos = df[df[\"binds\"] == 1].sample(n=min(pos_target, len(df[df[\"binds\"] == 1])), random_state=42)\n",
        "    df_neg = df[df[\"binds\"] == 0].sample(n=min(neg_target, len(df[df[\"binds\"] == 0])), random_state=42)\n",
        "    return pd.concat([df_pos, df_neg], ignore_index=True)\n",
        "\n",
        "# åŸ·è¡Œåˆ†å±¤æŠ½æ¨£\n",
        "train_dfs = []\n",
        "for target in targets:\n",
        "    df = stratified_sample(target[\"bb\"], target[\"pos\"], target[\"neg\"], strata_data)\n",
        "    train_dfs.append(df)\n",
        "\n",
        "# åˆä½µæ¨£æœ¬\n",
        "train_df = pd.concat(train_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
        "\n",
        "# æª¢æŸ¥çµæœ\n",
        "print(\"ğŸ” æª¢æŸ¥å»ºæ§‹å¡Šåˆ†å¸ƒ...\")\n",
        "bb1_unique = train_df[\"buildingblock1_smiles\"].nunique()\n",
        "bb2_unique = train_df[\"buildingblock2_smiles\"].nunique()\n",
        "bb3_unique = train_df[\"buildingblock3_smiles\"].nunique()\n",
        "\n",
        "print(f\"ç¸½æ¨£æœ¬æ•¸: {len(train_df)}\")\n",
        "print(f\"æ­£é¡è¨˜éŒ„æ•¸: {len(train_df[train_df['binds'] == 1])}\")\n",
        "print(f\"è² é¡è¨˜éŒ„æ•¸: {len(train_df[train_df['binds'] == 0])}\")\n",
        "print(f\"ç¨ç‰¹åˆ†å­æ•¸: {train_df['molecule_smiles'].nunique()}\")\n",
        "print(f\"buildingblock1_smilesç›¸ç•°è¨ˆæ•¸: {bb1_unique}ï¼ˆåŸå§‹271ï¼‰\")\n",
        "print(f\"buildingblock2_smilesç›¸ç•°è¨ˆæ•¸: {bb2_unique}ï¼ˆåŸå§‹693ï¼‰\")\n",
        "print(f\"buildingblock3_smilesç›¸ç•°è¨ˆæ•¸: {bb3_unique}ï¼ˆåŸå§‹872ï¼‰\")\n",
        "\n",
        "# å„²å­˜çµæœ\n",
        "train_df.to_csv(\"1030_40_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "qvJ49cg3Rf2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}