{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t8101349/group-project-202503/blob/main/gradio_web_0326.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install gradio\n",
        "!pip install rdkit\n",
        "!pip install scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install psutil"
      ],
      "metadata": {
        "id": "FIHfm3wryrz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 以上套件放進huggingface space requirement"
      ],
      "metadata": {
        "id": "DIRO1UmDs7t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import traceback\n",
        "from gradio.themes import Base\n",
        "from process import predict_process\n",
        "import os\n",
        "from rdkit import Chem\n",
        "import psutil\n",
        "import time\n",
        "\n",
        "# 放進huggingface space app.py\n",
        "\n",
        "# 記憶體資訊更新函數(測試用)\n",
        "def update_memory_info():\n",
        "    while True:\n",
        "        memory_info = psutil.Process().memory_info()\n",
        "        memory_mb = memory_info.rss / (1024 * 1024)  # 轉換為 MB\n",
        "        yield f\"RAM 使用量: {memory_mb:.2f} MB | CPU 使用率: {psutil.cpu_percent()}%\"\n",
        "        time.sleep(2)  # 每2秒更新一次\n",
        "\n",
        "\n",
        "# 設定頁面元件\n",
        "with gr.Blocks(\n",
        "    delete_cache=(3600, 7200),\n",
        "    theme=Base(primary_hue=\"cyan\", secondary_hue=\"teal\", neutral_hue=\"gray\"),\n",
        "    title=\"新藥預測工具\",\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        width: 100% !important;\n",
        "        max-width: 800px !important;\n",
        "        margin: 0 auto !important;\n",
        "        padding: 0.5rem;\n",
        "    }\n",
        "    .gradient-title h1 {\n",
        "        background: linear-gradient(45deg, #13A9E6, #3DD69E);\n",
        "        -webkit-background-clip: text;\n",
        "        background-clip: text;\n",
        "        color: transparent;\n",
        "        text-align: center;\n",
        "        font-size: clamp(2rem, 5vw, 3.5rem);\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    footer {\n",
        "        display: none !important;\n",
        "    }\n",
        "    .file-status {\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "    # 頂部的記憶體資訊框(測試用)\n",
        "    memory_box = gr.Textbox(\n",
        "        label=\"系統資源使用情況\",\n",
        "        value=\"RAM 使用量: 計算中... | CPU 使用率: 計算中...\",\n",
        "        elem_classes=[\"memory-info\"],\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"# 新藥預測工具\", elem_classes=[\"gradient-title\"])\n",
        "\n",
        "    with gr.Accordion(\"點此查看工具詳細說明\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "            **功能介紹：**\n",
        "            此工具可將 SMILES 字串的分子資料集根據機器學習模型預測出每個分子是否與指定的\n",
        "            蛋白質標靶(sEH, BRD4, HSA 其中之一)結合，快速篩選出可能的藥物分子資料集。\n",
        "\n",
        "            **操作說明：**\n",
        "            1. 上傳分子數據集\n",
        "            2. 確認檔案\n",
        "            3. 執行預測\n",
        "            4. 選擇下載格式\n",
        "            5. 產生預測檔案\n",
        "            6. 下載預測檔案\n",
        "\n",
        "            **上傳資料限制：**\n",
        "            1. 支援 CSV 與 Parquet 格式\n",
        "            2. 包含必要欄位\n",
        "            3. 檔案大小上限50MB\n",
        "            4. 資料筆數上限50萬筆\n",
        "\n",
        "            **必要欄位說明：**\n",
        "            - molecule_smiles: 分子的 SMILES 字串\n",
        "            - protein_name: 蛋白質名稱 (必須為 sEH, BRD4, HSA 其中之一)\n",
        "            \"\"\")\n",
        "\n",
        "    # 定義 state\n",
        "    state = gr.State(value={\n",
        "        \"df\": None,\n",
        "        \"result_df\": None,\n",
        "        \"file_uploaded\": False,\n",
        "        \"prediction_done\": False,\n",
        "        \"cancel_prediction\": False\n",
        "    })\n",
        "\n",
        "    with gr.Column():\n",
        "        file_input = gr.File(\n",
        "            label=\"上傳分子數據集，拖曳檔案至此或點擊上傳，上限50MB\",\n",
        "            file_types=[\".csv\", \".parquet\"],\n",
        "            type=\"filepath\"\n",
        "        )\n",
        "\n",
        "        confirm_btn = gr.Button(\"確認檔案\", variant=\"primary\")\n",
        "        file_status = gr.Textbox(\n",
        "            label=\"檔案確認狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            predict_btn = gr.Button(\"執行預測\", variant=\"primary\", interactive=False)\n",
        "            cancel_btn = gr.Button(\"取消預測\", variant=\"primary\", interactive=False)\n",
        "\n",
        "        predict_status = gr.Textbox(\n",
        "            label=\"預測狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            download_format = gr.Radio(\n",
        "                choices=[\"CSV\", \"Parquet\"],\n",
        "                label=\"選擇下載格式\",\n",
        "                value=\"CSV\"\n",
        "            )\n",
        "\n",
        "        generate_btn = gr.Button(\"產生下載檔案\", variant=\"primary\", interactive=False)\n",
        "        generate_status = gr.Textbox(\n",
        "            label=\"檔案生成狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        download_btn = gr.DownloadButton(\n",
        "            label=\"下載預測結果\",\n",
        "            variant=\"primary\",\n",
        "            interactive=False,\n",
        "            visible=True\n",
        "        )\n",
        "\n",
        "        download_status = gr.Textbox(\n",
        "            label=\"下載狀態\",\n",
        "            elem_classes=[\"file-status\"],\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "    # 檔案確認\n",
        "    def confirm_file(file, state):\n",
        "        if file is None:\n",
        "            return \"請上傳分子數據集！\", state\n",
        "        try:\n",
        "            if file.endswith('.csv'):\n",
        "                try:\n",
        "                    df = pd.read_csv(file, encoding=\"utf-8\")\n",
        "                except UnicodeDecodeError:\n",
        "                    df = pd.read_csv(file, encoding=\"Windows-1252\")\n",
        "            elif file.endswith('.parquet'):\n",
        "                df = pd.read_parquet(file)\n",
        "\n",
        "            required_columns = [\"molecule_smiles\", \"protein_name\"]\n",
        "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "            if missing_columns:\n",
        "                return f\"檔案缺少必要的欄位：{', '.join(missing_columns)}\", state\n",
        "\n",
        "            if len(df) > 500000:\n",
        "                return \"資料筆數超過 50 萬筆，請減少資料量！\", state\n",
        "\n",
        "            # 檢查特徵欄位的缺值\n",
        "            for column in required_columns:\n",
        "                if df[column].isnull().any():\n",
        "                    return f\"❌ 欄位 '{column}' 含有缺值，請檢查並補充完整數據！\", state\n",
        "\n",
        "            # 檢查 molecule_smiles 是否為有效 SMILES 格式\n",
        "            invalid_smiles = []\n",
        "            for idx, smiles in enumerate(df[\"molecule_smiles\"]):\n",
        "                try:\n",
        "                    mol = Chem.MolFromSmiles(smiles)\n",
        "                    if mol is None:\n",
        "                        invalid_smiles.append((idx, smiles))\n",
        "                except:\n",
        "                    invalid_smiles.append((idx, smiles))\n",
        "\n",
        "            if invalid_smiles:\n",
        "                error_msg = \"❌ 以下分子 SMILES 格式無效：\\n\"\n",
        "                for idx, smiles in invalid_smiles[:5]:  # 只顯示前5個錯誤避免訊息太長\n",
        "                    error_msg += f\"行 {idx + 1}: {smiles}\\n\"\n",
        "                if len(invalid_smiles) > 5:\n",
        "                    error_msg += f\"...還有 {len(invalid_smiles) - 5} 個無效 SMILES\\n\"\n",
        "                error_msg += \"請檢查並修正 SMILES 格式！\"\n",
        "                return error_msg, state\n",
        "\n",
        "            # 檢查 protein_name 是否為 sEH, BRD4 或 HSA\n",
        "            valid_proteins = {\"sEH\", \"BRD4\", \"HSA\"}\n",
        "            invalid_proteins = []\n",
        "            for idx, protein in enumerate(df[\"protein_name\"]):\n",
        "                if protein not in valid_proteins:\n",
        "                    invalid_proteins.append((idx, protein))\n",
        "\n",
        "            if invalid_proteins:\n",
        "                error_msg = \"❌ 以下蛋白質名稱無效（僅允許 sEH, BRD4 或 HSA）：\\n\"\n",
        "                for idx, protein in invalid_proteins[:5]:\n",
        "                    error_msg += f\"行 {idx + 1}: {protein}\\n\"\n",
        "                if len(invalid_proteins) > 5:\n",
        "                    error_msg += f\"...還有 {len(invalid_proteins) - 5} 個無效蛋白質名稱\\n\"\n",
        "                error_msg += \"請將蛋白質名稱修正為 sEH, BRD4 或 HSA！\"\n",
        "                return error_msg, state\n",
        "\n",
        "            state[\"df\"] = df\n",
        "            state[\"file_uploaded\"] = True\n",
        "            state[\"prediction_done\"] = False\n",
        "            state[\"cancel_prediction\"] = False  # 重置取消標誌\n",
        "\n",
        "            filename = os.path.basename(file)\n",
        "            return f\"✅ 已成功上傳檔案：{filename}，共 {len(df)} 筆資料\", state\n",
        "        except Exception as e:\n",
        "            error_details = traceback.format_exc()\n",
        "            print(f\"檔案處理錯誤：{str(e)}\\n{error_details}\")\n",
        "            return f\"❌ 檔案處理錯誤：{str(e)}\", state\n",
        "\n",
        "    # 執行預測\n",
        "    def run_prediction(state):\n",
        "        if not state[\"file_uploaded\"] or state[\"df\"] is None:\n",
        "            return \"❌ 請先上傳並確認檔案！\", state\n",
        "        try:\n",
        "            # 重置取消標誌\n",
        "            state[\"cancel_prediction\"] = False\n",
        "\n",
        "            # 檢查取消狀態（在 predict_process 中實現）\n",
        "            result_df = predict_process(state[\"df\"], cancel_flag=lambda: state[\"cancel_prediction\"])\n",
        "            if state[\"cancel_prediction\"]:\n",
        "                return \"❌ 預測已取消！\", state\n",
        "\n",
        "            state[\"result_df\"] = result_df\n",
        "            state[\"prediction_done\"] = True\n",
        "            return f\"✅ 預測完成！共處理 {len(result_df)} 筆資料\", state\n",
        "        except Exception as e:\n",
        "            error_details = traceback.format_exc()\n",
        "            print(f\"預測錯誤：{str(e)}\\n{error_details}\")\n",
        "            return f\"❌ 預測錯誤：{str(e)}\", state\n",
        "\n",
        "    # 取消預測函數\n",
        "    def cancel_prediction(state):\n",
        "        state[\"cancel_prediction\"] = True\n",
        "        return \"正在取消預測...\", state\n",
        "\n",
        "    # 產生下載檔案\n",
        "    def generate_file(format_choice, state):\n",
        "        import tempfile\n",
        "        if not state[\"prediction_done\"] or state[\"result_df\"] is None:\n",
        "            return None, \"❌ 請先執行預測！\", state\n",
        "        try:\n",
        "            temp_dir = tempfile.gettempdir()\n",
        "            if format_choice == \"CSV\":\n",
        "                filename = \"prediction.csv\"\n",
        "                filepath = os.path.join(temp_dir, filename)\n",
        "                state[\"result_df\"].to_csv(filepath, index=False)\n",
        "            else:\n",
        "                filename = \"prediction.parquet\"\n",
        "                filepath = os.path.join(temp_dir, filename)\n",
        "                state[\"result_df\"].to_parquet(filepath, index=False)\n",
        "            return filepath, f\"✅ 已生成 {filename}，點擊下方按鈕即可下載\", state\n",
        "        except Exception as e:\n",
        "            error_details = traceback.format_exc()\n",
        "            print(f\"生成檔案錯誤：{str(e)}\\n{error_details}\")\n",
        "            return None, f\"❌ 生成檔案錯誤：{str(e)}\", state\n",
        "\n",
        "    # 下載完成後更新狀態\n",
        "    def update_download_status(filepath):\n",
        "        if filepath:\n",
        "            filename = os.path.basename(filepath)\n",
        "            return f\"✅ 已下載 {filename}\"\n",
        "        return \"❌ 下載失敗\"\n",
        "\n",
        "    # 啟動記憶體監控（測試用）\n",
        "    demo.load(\n",
        "        fn=update_memory_info,\n",
        "        inputs=None,\n",
        "        outputs=memory_box\n",
        "    )\n",
        "\n",
        "    # 事件綁定\n",
        "    confirm_btn.click(\n",
        "        fn=confirm_file,\n",
        "        inputs=[file_input, state],\n",
        "        outputs=[file_status, state]\n",
        "    ).then(\n",
        "        fn=lambda status_text: gr.update(interactive=\"✅\" in status_text),\n",
        "        inputs=file_status,\n",
        "        outputs=predict_btn\n",
        "    )\n",
        "\n",
        "    predict_btn.click(\n",
        "        fn=run_prediction,\n",
        "        inputs=state,\n",
        "        outputs=[predict_status, state]\n",
        "    ).then(\n",
        "        fn=lambda status_text: gr.update(interactive=\"✅\" in status_text),\n",
        "        inputs=predict_status,\n",
        "        outputs=generate_btn\n",
        "    ).then(  # 預測開始時啟用取消按鈕，完成時禁用\n",
        "        fn=lambda status_text: gr.update(interactive=\"✅\" not in status_text and \"❌\" not in status_text),\n",
        "        inputs=predict_status,\n",
        "        outputs=cancel_btn\n",
        "    )\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_file,\n",
        "        inputs=[download_format, state],\n",
        "        outputs=[download_btn, generate_status, state]\n",
        "    ).then(\n",
        "        fn=lambda filepath, status: gr.update(value=filepath, interactive=\"✅\" in status),\n",
        "        inputs=[download_btn, generate_status],\n",
        "        outputs=download_btn\n",
        "    )\n",
        "\n",
        "    download_btn.click(\n",
        "        fn=update_download_status,\n",
        "        inputs=download_btn,\n",
        "        outputs=download_status\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(max_file_size=50 * 1024 * 1024)"
      ],
      "metadata": {
        "id": "SzcR4GR_b3Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# 放進huggingface space process.py\n",
        "\n",
        "def smiles_to_morgan_fingerprint(smiles, n_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(n_bits, dtype=int)\n",
        "    else:\n",
        "        generator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
        "        return np.array(generator.GetFingerprint(mol), dtype=int)\n",
        "\n",
        "def predict_process(df, cancel_flag=None):\n",
        "    # 載入模型\n",
        "    model_path = hf_hub_download(repo_id='sinanju/model_voting', filename='voting_model.bin')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # 保留分子式\n",
        "    mol_smiles = df['molecule_smiles']\n",
        "\n",
        "    # 對 'molecule_smiles' 欄位進行轉換，並檢查取消\n",
        "    fingerprint_list = []\n",
        "    for smiles in df['molecule_smiles']:\n",
        "        if cancel_flag and cancel_flag():  # 檢查取消標誌\n",
        "            return None\n",
        "        fingerprint_list.append(smiles_to_morgan_fingerprint(smiles))\n",
        "    df['molecule_smiles'] = fingerprint_list\n",
        "    df.columns = df.columns.astype(str)\n",
        "\n",
        "    # 轉成 int8 以節省記憶體\n",
        "    int_cols = df.select_dtypes(include=['int64']).columns\n",
        "    for col in int_cols:\n",
        "        if cancel_flag and cancel_flag():  # 檢查取消標誌\n",
        "            return None\n",
        "        df[col] = df[col].astype(np.int8)\n",
        "\n",
        "    # 處理指紋數據和蛋白質編碼\n",
        "    fingerprints_df = pd.DataFrame(df['molecule_smiles'].to_list())\n",
        "    protein_onehot = pd.get_dummies(df['protein_name'], prefix='protein').astype(int).reset_index(drop=True)\n",
        "    X_test = pd.concat([fingerprints_df, protein_onehot], axis=1)\n",
        "    X_test.columns = X_test.columns.astype(str)  # 統一欄位名稱為字串\n",
        "\n",
        "    # 預測機率並轉為二元分類\n",
        "    if cancel_flag and cancel_flag():  # 檢查取消標誌\n",
        "        return None\n",
        "    probabilities = model.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.5\n",
        "    predictions = (probabilities >= threshold).astype(int)\n",
        "\n",
        "    # 產生新的 id\n",
        "    df['id'] = range(1, 1 + len(df))\n",
        "\n",
        "    # 建立結果 DataFrame\n",
        "    result_df = pd.DataFrame({\n",
        "        'id': df['id'],\n",
        "        'molecule_smiles': mol_smiles,\n",
        "        'protein_name': df['protein_name'],\n",
        "        'binds': predictions\n",
        "    })\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "hbo5B48XtMa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}